---
title: "1_eflalo_tacsat_quality_control"
author: "Roi & Mike"
date: "2023-09-14"
output: html_document
--- 
```{r setup, include=TRUE, eval=FALSE}
 
knitr::opts_chunk$set(echo = TRUE, eval = FALSE)

options(dplyr.width = Inf, dplyr.print_min = 500)
library(vmstools)
library(dplyr)
library(ggplot2)
library(sf)
```

Set the working directory if it is not already set to the data folder.

 
```{r set wd, include=TRUE, eval=FALSE}
 setwd('./../../data')
```

Load the data created via by the previouis workflow.
 
```{r load data, include=TRUE, eval=FALSE}

 load(".\\workflow_outputs\\eflalo.RData")
load(".\\workflow_outputs\\tacsat.RData")
```



## Clean the EFLALO data

### 1.1  Number of EFLALO records and fishing Log Events records

The EFLALO data requires cleaning as the majority of the data is manually input by humans, such as species, weight, time of departure and return. This leaves room for human error, which must be accounted for in the processing. In this section, the number of log events per trip is checked; if this number is unrealistic, this would be an example of an incorrect input and should be dealt with.

Checking the eflalo data using the dplyr package is simple, as it allows multiple functions to be chained together using the %>% symbol combination. Under Q1.1, the groupby, summarise and arrange functions are all applied to the dataset eflalo_gbw, without the need to separate the commands into multiple lines of code.

This line groups all entries that share the same FT_REF, using groupby(). Obviously there would be some loss of data if we simply applied each record of the next if it shared a trip reference, but here it is simply counting the number of records per trip, so a tally is taken using summarise(). Finally, arrange() sorts them into descending order.

As can be seen, the output is each trip reference, followed by the n column displaying the number of records that occurred.

Following this, the number of log events is calculated and individual trip references can be inspected if they present unrealistic log event or record numbers.

 
```{r count records & log events, include=TRUE, eval=FALSE}
 
## Q1.1: How many overall records are by  trip?
res2 = eflalo_fs%>%group_by(FT_REF) %>% summarise(n = n()) %>% arrange(desc(n))
ggplot(res2, aes( n )) + geom_histogram()


## Q1.2: How many log events are by  trip?  ( LOG EVENTS ONLY EXIST IN E-LOGBOOKS from GEOFISH SOURCE / CR does not collect LOG EVENTS)


res21= eflalo_fs%>%distinct (FT_REF, LE_ID , trip_days) %>%group_by(FT_REF, trip_days)%>%summarise(n = n())%>%arrange(desc(n))
ggplot(res21, aes( n )) + geom_histogram()
```

Identifying trips with more than one assigned gear. 

 
```{r multi-gear trips, include=TRUE, eval=FALSE}
 
# Q1.2.1 . How do we assign GEAR and ICES RECTANGLE to iVMS/VMS TACSAT records . Example of different cases: 


      ###  1st: FISHING TRIP WITH > 1 GEARS REPORTED 

        ## Identify trips with more than 1 trip 

         trips_with_more_than_1_gear = eflalo_fs %>% distinct(FT_REF, LE_GEAR )%>% group_by(FT_REF ) %>% mutate ( rn = row_number ( ) ) %>% filter ( rn > 1) 
         trips_with_more_than_1_gear%>% arrange( rn , FT_REF , LE_GEAR)
         
         eflalo_fs %>% filter( FT_REF %in%  ( trips_with_more_than_1_gear %>%select (FT_REF ) %>%  pull() ) ) %>%
           distinct (FT_REF , LE_GEAR) %>%  arrange ( FT_REF )

```

Explore one of these trips in more detail. Change the trip reference number as required.

 
```{r , include=TRUE, eval=FALSE}
 
eflalo_fs %>% filter(FT_REF == 610715898 )%>%mutate ( tt = FT_DDATIM   + ( ( FT_LDATIM - FT_DDATIM )   / 2))
```

The best solution to the problem of multiple gears for one trip is to merge the gears into one unique, combined gear. So these trips will have a merged gear and metier defined: e.g. a trip using GN and FPO would have a gear defined as : GN_FPO.

 
```{r , include=TRUE, eval=FALSE}
 
         eflalo_fs_mult_gears = eflalo_fs %>% filter(FT_REF %in% trips_with_more_than_1_gear$FT_REF )
         
         trips_mult_gears_comb = eflalo_fs_mult_gears %>% 
                                 distinct(FT_REF, LE_GEAR, LE_MET ) %>% arrange( FT_REF , LE_GEAR, LE_MET) %>%
                                 group_by( FT_REF  )  %>% 
                                 mutate ( LE_GEAR_C = paste0  ( LE_GEAR, collapse =  "_"),
                                          LE_MET_C =  ifelse( LE_MET != 'NULL',  paste0  ( LE_MET, collapse =  "_"), LE_MET  ) ) %>%
                                 select (FT_REF, LE_GEAR_C, LE_MET_C )
         
         eflalo_fs_mult_gears %>% inner_join(trips_mult_gears_comb, by  = 'FT_REF')
         
         
         eflalo_fs %>% filter(FT_REF %in% trips_with_more_than_1_gear$FT_REF ) %>%  group_by( FT_REF  ) %>%mutate (LE_KG_TOT  = sum ( LE_KG)) %>%
           group_by( FT_REF, LE_GEAR ) %>% reframe ( LE_KG_TOT = LE_KG_TOT, LE_KG_TOT_GEAR =  sum ( LE_KG )) %>%
           distinct ( FT_REF , LE_GEAR, LE_KG_TOT, LE_KG_TOT_GEAR) %>% 
           mutate (LE_KT_PROP = LE_KG_TOT_GEAR / LE_KG_TOT  ) %>% print(n = 110 )
```

Further exploration into a trip identified with more than one gear.

 
```{r , include=TRUE, eval=FALSE}
 
    eflalo_fs %>% filter(FT_REF == 610715898 )%>%mutate ( tt = FT_DDATIM   + ( ( FT_LDATIM - FT_DDATIM )   / 2))
         
      eflalo_sel = eflalo_fs %>% filter(FT_REF == 610715898 ) %>% as.data.frame()
      
      tacsat_sel = tacsat_fs %>% filter(SI_FT == 610715898 & SI_SP >=0 & SI_SP <= 5) %>%
        arrange( SI_DATIM) %>% left_join( eflalo_sel %>% filter(FT_REF == 610715898), by = c("SI_FT" = "FT_REF", "SI_DATE" = "LE_CDAT"))
      
      tacsat_plot = tacsat_fs %>% filter(SI_FT == 610809285  & SI_SP >=2 & SI_SP <= 4) %>% arrange( SI_DATIM) 
```



 
```{r , include=TRUE, eval=FALSE}
 
      ### 2 GEARS WITH VMS 
      eflalo_fs %>% filter(FT_REF == 610715898) %>% as.data.frame()


      ##NOT iVMS record associated to trips with more than 1 log event records( use of multiple gears) 
      
      
      ### EXAMPLE OF A TRIP WITH 3 DAYS DURATION AND ONE GEAR REPORTED
      
      eflalo_sel %>% filter(FT_REF == 610691287)
      eflalo_fs %>% filter(FT_REF == 610691287) %>%as.data.frame()
```

### 1.2 Duration of the fishing trips 

Unrealistic trip days suggest human error, so the following code calculates the number of days each trip reference supposedly spanned. 

From the code in section 1.2, the number of days is produced, so outliers can be seen. It is evident there are some unrealistic trip times, with one trip supposedly lasting 366 days - likely the wrong year was input. These trips can be filtered out in section 1.1.1, which finds trips which took 10 days or less and assigns them to 'trips_in'. This number cam be edited depending on the dataset. Then, eflalo_gbw is filtered to only include trip references which are present in 'trips_in', successfully removing trips with unrealistic time frames. 

 
```{r , include=TRUE, eval=FALSE}
 

## Observe the trips with more days duration by data SOURCE . Identify outliers and potential errors in Departure and Landing dates. 

eflalo_fs %>% select(trip_days, SOURCE, FT_REF, FT_DDATIM,FT_LDATIM,  VE_LEN) %>% arrange( SOURCE, desc( trip_days )) %>% filter( SOURCE == 't3')

## Q2.1: If outliers have been identified? Should those entries be removed or can the data be fixed?

## Filter out those outlying trip durations

trips_outliers =  eflalo_fs %>% 
                  filter(SOURCE == 't3' & trip_days > 5 ) %>% 
                  select(FT_REF) %>%
                  distinct(FT_REF) %>%
                  pull()

  
length ( trips_outliers )

# < 5 days trips : 9194
# < 10 days trips : 9207
# total trips : 9228

eflalo_ti = eflalo_fs %>% filter ( ( ! FT_REF %in% trips_outliers ) ) 

dim ( eflalo_ti )
dim(eflalo_fs)
```

# 1.3 Search for catch records with unlikely landing values

Landings can also present unrealistic numbers; by setting a threshold, unreasonably high landings numbers can be identified and removed. Per-species thresholds can be set using log10, where the final value will vary based on the species, so a blanket threshold for all species is not set. The results of the filter can be used in the subsequent code to look into why their landing weights are exceeding expected values.
  
  
  
```{r , include=TRUE, eval=FALSE}
 

## Select a logarithm scale landing weight threshold ( e.g. 1.5)

landingThreshold = 1.5

## Identify the records with species captures over expected thresholds 

eflalo_fs %>%
  group_by(  LE_GEAR, LE_SPE) %>%
  arrange( LE_GEAR, LE_SPE,  LE_KG  ) %>%
  mutate (diff_le_kg =   lead ( log10 ( LE_KG ), n = 1) - log10 ( LE_KG) ) %>% #select (rr1, rr2)
  filter(  ! is.na ( diff_le_kg ) ) %>%              ## filter those values that are not NA ( NULL ) 
  summarise ( max = max(diff_le_kg) , min = min(diff_le_kg) ) %>%
  filter ( max > landingThreshold ) %>%
print(n=200)



## Explore those captures with high difference identified and decide if must be removed from records 

eflalo_fs %>% filter( LE_GEAR == 'GTR' & LE_SPE == 'SOL') %>% select ( LE_KG) %>% arrange( desc(LE_KG) )
eflalo_fs %>% filter(LE_GEAR == 'FPO' & LE_SPE == 'TGS') %>% select ( LE_KG)%>%arrange(desc(LE_KG))
eflalo_fs %>% filter(LE_GEAR == 'OTB' & LE_SPE == 'BSS') %>% select ( LE_KG)%>%arrange(desc(LE_KG))

## Explore specific fishing trip information for outliers values

eflalo_fs %>% filter( LE_GEAR == 'GTR' & LE_SPE == 'SOL' & LE_KG  > 1000)  
eflalo_fs %>% filter( FT_REF == 610699215 ) ## change trip id based in the analysis
## Filter values no required out 
```

# 1.4/1.5 Check for NA's in catch records ----------------------------------------------------------

It is useful to check for NA values in numerical or date columns columns as if calculations are enacted on these, it may produce NA values as the result. Filtering to results with NA values allows them to be investigated and to see if they may cause issues further into the analysis.

```{r , include=TRUE,eval = FALSE}

eflalo_fs %>% filter(  is.na ( LE_KG ))

eflalo_fs %>% filter( is.na(FT_DDATIM) | is.na(FT_LDATIM) )
```

# 1.6  Remove non-unique trip numbers -----------------------------------------------------------------------------

Duplicated trips cause inaccuracies in landings data and therefore should be removed. duplicate analysis is creating a variable which provides a boolean response to if a trip is duplicated or not, by checking the trip and vessel references and the departure/landing times. These trips can be investigated by the code in the third block. Finally, trips IDs that are identified as duplicates can be removed via common FT_REF with the duplicated_trips dataset.

```{r , include=TRUE,eval = FALSE}
duplicate_analysis = eflalo_fs%>%
  distinct(VE_REF , FT_REF,  FT_DDAT, FT_LDAT)%>%
  group_by(VE_REF, FT_DDAT, FT_LDAT)%>%
  summarise( number_trips = n() ) %>%
  mutate ( duplicated = ifelse( number_trips >  1, TRUE , FALSE    )  )  
```

Explore the data for duplicated trips

```{r duplicate trips 1, include=TRUE,eval = FALSE}
## Explore duplicated trips details

## How many are there?
eflalo_fs %>% left_join (duplicate_analysis , by = c ( 'VE_REF', 'FT_DDAT', 'FT_LDAT'))%>%
  filter(duplicated == TRUE) %>% 
  arrange(VE_REF, FT_REF, LE_SPE) %>% length()

## Explore them 
eflalo_fs %>% left_join (duplicate_analysis , by = c ( 'VE_REF', 'FT_DDAT', 'FT_LDAT'))%>%
  filter(duplicated == TRUE) %>% 
  arrange(VE_REF, FT_REF, LE_SPE)
```

```{r duplicate trips 2, include=TRUE,eval = FALSE}

## Identify the trip id's that are duplicated 

duplicate_trips =  eflalo_fs%>%
  left_join (duplicate_analysis , by = c ( 'VE_REF', 'FT_DDAT', 'FT_LDAT'))%>%
  group_by(FT_REF)%>%
  mutate ( number_records = n ())%>% 
  ungroup()%>%
  filter(duplicated == TRUE) %>%
  distinct(VE_REF, FT_REF, FT_DDAT ,  FT_LDAT , number_records) %>%
  arrange( VE_REF,   FT_DDAT ,  FT_LDAT , desc( number_records) )%>%
  ungroup()%>%
  group_by(VE_REF, FT_DDAT,FT_LDAT)%>%
  mutate(r_num = row_number() )%>%
  filter(r_num > 1)%>%
  select(FT_REF)%>%
  pull()

## Filter out the duplicated trips

eflalo_fs =   eflalo_fs %>%
  filter( ! FT_REF %in% duplicate_trips   ) 
```

# 1.7 Remove records with arrival date before departure date  ------------------------------------------------------------

Another example of human error in input are trips which apparently ended before they began, these can be easily removed thanks to the trip_days column created previously. If the trip days are less than or equal to 0, they are considered impossible.


```{r filter departure arrival overlap, include=TRUE,eval = FALSE}
## Use the field created with trip duration: trip_days
## A value of 0 or negative would means departure and landing dates are same or reversed

eflalo_fs %>% filter(trip_days <= 0 )
```

### 1.8 Remove trips which overlap with another trip

Furthermore, a vessel cannot be on two separate trips at once, so trips which overlap one another cannot feasibly occur. The VMS locations of these trips will cause issues as they are technically suggesting a vessel is in two places at once. These trips must be corrected or deleted, this decision can be made on a case by case basis, following the following filtering, which will pull these trips out conveniently.


```{r filter overlaps different trips, include=TRUE,eval = FALSE}
overlaps_analysis =  eflalo_fs%>%distinct(VE_REF, FT_REF, FT_DDATIM, FT_LDATIM)%>%
  arrange(VE_REF, FT_DDATIM)%>%
  group_by(VE_REF)%>%
  mutate( overlaps = FT_LDATIM > lead (FT_DDATIM)   )



## Check what vessel and trips dates are overlapping

overlaps_analysis%>%
  filter ( overlaps == TRUE)



## Filter the trips details for the vessel during the overlapping dates 
  ## Replace VE_REF and DATES based on previous code line results. 

overlaps_analysis %>%
  filter( VE_REF == 'A17444' & FT_DDATIM > '2022-03-19' & FT_DDATIM < '2022-04-22'  ) %>%
  arrange( VE_REF, FT_DDATIM)

eflalo_fs%>%
  filter( VE_REF == 'A17444' & FT_DDATIM > '2022-03-19' & FT_DDATIM < '2022-04-22'  ) %>%
  group_by(FT_REF)%>%
  summarise(numb = n())
```


```{r overlapping/duplicated trips exploration, include=TRUE,eval = FALSE}
## Following this analysis we have found out that these trips are duplicated 
## The three overlapping trips have the same reported species and details

eflalo_fs %>% filter( FT_REF %in% c(10343311296 , 10343333399  ))


eflalo_fs %>% filter( FT_REF %in% c(610787207, 610791817))

eflalo_fs %>% filter( FT_REF %in% c(610738857, 610735265)) 
```


## Clean the TACSAT data

### 2.1 Load spatial auxiliary data

Spatial data is necessary for analysing VMS data. It can be loaded into R as follows.


```{r load spatial data, include=TRUE,eval = FALSE}

welsh_marine_area = st_read ( dsn = '.\\spatial_layers\\wales_plan_area.geojson' )
port_500m = st_read( dsn = '.\\spatial_layers\\welsh_ports_ammended_0_005.geojson')
land = st_read ( dsn = '.\\spatial_layers\\Europe_coastline_poly.shp')
europe_aoi = st_read ( dsn = '.\\spatial_layers\\europe_aoi.geojson')  ###load the layer with crop are of interest 
ICESareas = st_read(dsn = '.\\spatial_layers\\ICES_rectangles.geojson')
ices_rect_welsh = st_read(dsn = '.\\spatial_layers\\ICES_rectangle_welsh.geojson')
```

Convert the data to the espg:4326 crs so that all data pieces are in the same crs.


```{r set crs, include=TRUE,eval = FALSE}

welsh_marine_area %>% st_crs()  ## WGS 84 EPSG: 4326
port_500m %>% st_crs()   ## WGS 84
land  %>% st_crs() 
ICESareas = ICESareas %>% st_transform(4326)

land_4326 = land %>% st_transform( 4326 )   ## reproject the sf object ( spatial layer ) into a new coordinate system 

plot( land_4326)
```

Define a bounding box for Europe. This is used to reduce the size of the land data, to reduce the processing power needed for plotting. Additionally, the view frame will be much closer in and therefore more detail will be visible.

```{r europe aoi, include=TRUE,eval = FALSE}

aoi = st_bbox( c( xmin = -15, xmax = 3, ymax = 60, ymin = 47), crs = st_crs( 4326 )) ## Define our area of intenrest.  4326 is id for WGS1984 unprojected coordinate system 

europe_aoi = st_crop (x = land_4326, y = aoi)  ## clip/crop the whole European layer to our of interest

plot( europe_aoi)

head(eflalo_fs)
```

Filter the tacsat data to limit it to the trips in the eflalo data.

```{r trips in clean eflalo, include=TRUE,eval = FALSE}

trips_in_clean_eflalo = eflalo_fs %>% distinct(FT_REF)%>%pull() 

 
tacsat_fs -> bk # creates a backup of tacsat_fs
tacsat_fs = tacsat_fs %>% filter( SI_FT %in%  trips_in_clean_eflalo  ) # filter tacsat data to trips in eflalo
```

Explore the tacsat data to investigate the number of trips the number of trips within each respective dataset, which are common?

```{r investigate common trips, include=TRUE,eval = FALSE}

# Q1 : Number of trips in tacsat (iVMS) present in eflalo 

tacsat_fs %>% mutate(inboth = SI_FT %in% trips_in_clean_eflalo )%>%select(inboth)%>%table()

# Q2 : Number of trips in eflalo present in tacsat (iVMS)  

eflalo_fs %>%distinct(FT_REF)%>% mutate(inboth = FT_REF %in% ( tacsat_fs%>%distinct(SI_FT)%>%pull())  )%>%select(inboth)%>%table()
```

Analyse the trips which do not have related tacsat information due to potential human error, such as forgetting to activate the tacsat box. Or from being prior to 16-02-2022, when iVMS was introduced.


```{r ft_ref not in tacsat, include=TRUE,eval = FALSE}

ft_ref_not_in_tacsat = eflalo_fs %>%distinct(FT_REF)%>% mutate(inboth = FT_REF %in% ( tacsat_fs%>%distinct(SI_FT)%>%pull())  )%>%
  filter ( inboth == FALSE)

res1 = eflalo_fs %>% filter( FT_REF %in% (ft_ref_not_in_tacsat %>% select (FT_REF) %>% pull() ) ) %>% 
        filter( FT_DDAT > '2022-02-15')
```

Explore the data.


```{r explore , include=TRUE,eval = FALSE}

res1 %>%distinct(FT_DDAT)%>%pull()
res1 %>%distinct(VE_REF, FT_REF ) %>% group_by(VE_REF)%>%tally() %>%arrange(desc(n))
eflalo_fs %>%distinct(VE_REF)
res1  %>% distinct(VE_REF)
res1%>% summarise(min = min (FT_DDAT), max = max( FT_DDAT))
```

Explore a specific trip.

```{r single trip exploration, include=TRUE,eval = FALSE}

eflalo_fs %>% filter( VE_REF == 'C20757') %>% distinct(FT_REF)
tacsat_fs %>% filter( VE_REF == 'C20757') %>% distinct(SI_FT)

tacsat_fs %>% filter( VE_REF == 'C20757')%>%dim()

tacsat_fs %>% summarise(min = min (SI_DATE), max = max( SI_DATE))

dim(tacsat_fs)
```

### 2.2 Remove VMS pings outide ICES areas

Convert spatial grid references to match so the datasets can be used in conjunction for analysis. Next, remove any VMS pings which do not fall inside ICES areas.

```{r edit spatial grid references, include=TRUE,eval = FALSE}

ia =  ICESareas%>% 
      sf::st_as_sf() %>% 
      sf::st_make_valid() %>% 
      sf::st_transform(4326)  

overs = 
        tacsat_fs  %>% 
        sf::st_as_sf(coords = c("SI_LONG", "SI_LATI")) %>% 
        sf::st_set_crs(4326) %>% 
        sf::st_intersects(ia)

tacsat_fs = tacsat_fs[lengths(overs) > 0,]
```

Remove duplicate records.

```{r duplicates removal, include=TRUE,eval = FALSE}

tacsat_fs%>%
  group_by(VE_REF, SI_LATI, SI_LONG , SI_DATIM ) %>%
  filter( n() > 1) %>%
  arrange(VE_REF, SI_DATIM, SI_LATI, SI_LONG)

## From the overlap trip analysis done with EFLALO we can identify if the duplicated VMS locations correspond to those overlapping trips 

overlaps_analysis %>% filter(FT_REF %in% c( '610736051', '610738638') ) 

##  This confirms that these trips overlaps and therefore the VMS location is duplicated and assigned to the both trips
## To fix this error will require correct overlapping trips and reassign the trip identifiers to VMS locations 
```

Remove points that cannot be possible. Points which supposedly exist outside the extent of earth's longitude and latitude scales can simply be removed with the following code.

```{r remove impossible points, include=TRUE,eval = FALSE}

tacsat_fs = tacsat_fs %>% filter(abs(SI_LATI) < 90 | abs(SI_LONG) < 180)
tacsat_fs = tacsat_fs %>% filter(SI_HE >= 0 | SI_HE <= 360)
tacsat_fs %>% filter(SI_SP > 30 ) 
```

### 2.5 Remove points which are pseudo duplicates as they have an interval rate < x minutes

As VMS systems ping regularly at 2 hour intervals, double points are almost certainly duplicates, so they can be removed. To do this, R must know where the points are located, so it the TACSAT data must be converted into a spatial object using the sf package. 

Using the interval between pings on records with the same trip reference, records which have pinged too frequently in short succession can be identified.

```{r remove pseudo-duplicate points, include=TRUE,eval = FALSE}

tacsat_fs_geom = tacsat_fs %>% st_as_sf( ., coords = c("SI_LONG" ,"SI_LATI"), crs = 4326 , remove = FALSE)

st_write( tacsat_fs_geom, dsn = ".\\workflow_outputs\\tacsat_fs.geojson", layer = "tacsat_fs.geojson")

## Q1: What is the minimum expected time interval between iVMS positions

## Use that value to filter potential pseudo-duplicates ( values below the minimum expected interval)

minInterval = 1 / 60 ## 1 minute converted in hours (0.01666667 hours)

tacsat_fs_geom = tacsat_fs_geom%>%ungroup()%>%
  group_by(VE_REF, SI_FT)%>% arrange (VE_REF, SI_DATIM)%>%
  mutate (INTV =  difftime(SI_DATIM , lag(SI_DATIM), units = "hours" )  )%>% ## Calcualte the difference between a iVMS loction time stamp and previous location to calcualte a fishign effort in a given location
  mutate(interval_mean = mean(INTV , na.rm = T))%>% ## Calcualte the mean to replace the NA's interval when a VMS location is the 1st of a trip and cannot calculate with a prev. iVMS location
  mutate(INTV = ifelse( is.na(INTV), interval_mean, INTV ))%>%  ## Convert the NA's into a effort represented by the mean of that vessel durign given trip
  select(- interval_mean) %>%ungroup()



##Q2: Check the structure of TACSAT . Did the field types changed?

str(tacsat_fs_geom) 

##Q3: Calculate the minimum , maximum  and mean intervals in our data 

tacsat_fs_geom%>%filter(!is.na(INTV))%>%group_by(SOURCE) %>% summarise(minIntv = min(INTV), maxIntv = max (INTV), meanIntv = mean(INTV))#*60


tacsat_fs_geom%>%filter(!is.na(INTV))%>%group_by(INTV)%>%tally()%>%arrange(desc(n))

##Q4: Explore the intervals with a histogram. Outliers are detected? Can you fix or remove the wrong records?

ggplot(tacsat_fs_geom%>%filter(INTV < 4), aes(INTV) ) + geom_histogram(bins = 50)

## Q5: Use the filter to explore the large intervals records. Take the VE_REF and SI_FT to explore the trip 

tacsat_fs_geom%>%filter(INTV >5 )%>%arrange(VE_REF, SI_DATIM)%>%print(n= 100)%>%select(VE_REF, SI_FT) %>%
as.data.frame()

##Q5.1: Can you check the resulting intervals for a given vessel and trip id           

tacsat_fs_geom%>%filter ( VE_REF == 'C20757' &  SI_FT == '610808700'  ) %>%arrange(SI_DATIM)

##Q5.2: Plot the locations of the given trip to understand spatial patterns of a given trip

tacsat_fs_geom%>%filter ( VE_REF == 'C20757' &  SI_FT == '610808700'  )%>%
  mutate(largeIntv   = ifelse(INTV > 1 , TRUE , FALSE)) %>%
  ggplot( ) + geom_sf(aes(color = largeIntv)) + 
  geom_sf_label ( aes(label = ifelse ( INTV > 30, round(INTV, 1), NA )),  nudge_x = 0.05  ) + theme_minimal()
```

### 2.6 Remove points within harbours

Points within harbours are identified by their spatial intersection with the port_3km dataset. This action is completed via a left join, which retains all the data entries in the left table (TACSAT data) and applies the information from corresponding entries in the port_3km dataset.

These points can be plotted as shown below, using ggplot, which adds the Welsh marine area, the chosen ports which are selected within the quotation marks and the vms points which are located inside the ports. Finally, the boundary of the plot is specified so the plot is focused on the area of interest.

```{r remove points in harbours, include=TRUE,eval = FALSE}

tacsat_fs_ports = tacsat_fs_geom %>%
  st_join ( port_500m %>% select ( Name, District_N) , join = st_intersects, left = T) %>%
  mutate  ( SI_HARB  = ifelse ( is.na ( Name  ), FALSE , TRUE))  %>%
  select ( - names(port_500m%>% select ( Name, District_N)))
```

Plot this data.

```{r plot 1, include=TRUE,eval = FALSE}

getwd()
st_write( tacsat_fs_ports, dsn = paste0(".\\workflow_outputs\\spatial\\tacsat_port_welsh.geojson"), layer = "tacsat_port_welsh.geojson")      

##Q2: Plot the ports and iVMS locations when in port

ggplot() + 
  geom_sf ( data = welsh_marine_area) + 
  geom_sf(data = port_500m %>% filter (Name %in% c( 'Milford Haven', 'Cardigan') )) +
  geom_sf ( data = tacsat_fs_ports %>% slice(1:50000), aes( color  = SI_HARB ) )+ 
  theme_minimal() + 
  coord_sf( xlim = c(- 5.5, -4), ylim = c(51.6, 52.2) )
```

```{r plot 2, include=TRUE,eval = FALSE}

ggplot() + 
  geom_sf ( data = welsh_marine_area) + 
  geom_sf(data = port_500m %>% filter (Name %in% c( 'Milford Haven', 'Cardigan') )) +
  geom_sf ( data = tacsat_fs_ports %>% slice(1:50000), aes( color  = SI_HARB ) )+ 
  theme_minimal() + 
  coord_sf( xlim = c(- 5.5, -4), ylim = c(51.6, 52.2) )
```

### 2.7 Remove points on land

```{r remove points on land, include=TRUE,eval = FALSE}

tacsat_fs_land = tacsat_fs_ports %>% 
  st_join( europe_aoi , join = st_intersects, left = T )%>%
  mutate  ( SI_LAND  = ifelse ( is.na ( Id ), FALSE ,TRUE))%>%
  select ( - names(europe_aoi) )  

st_write( tacsat_fs_land, dsn = ".\\workflow_outputs\\spatial\\tacsat_fs_land.geojson", layer = "tacsat_fs_land.geojson", append=FALSE )      
```

Investigate the points on land.

```{r investiagte points on land, include=TRUE,eval = FALSE}

tacsat_fs_land%>%st_drop_geometry()%>%group_by(SI_LAND)%>%count()


##Q2: Plot the iVMS locations when in land

ggplot() + 
  geom_sf ( data = welsh_marine_area) + 
  #geom_sf(data = port_3km%>%filter (port %in% c( 'Milford Haven', 'Cardigan') )) +
  geom_sf ( data = tacsat_fs_land%>%slice(1:50000), aes(color  = SI_LAND ))+ theme_minimal() + 
  coord_sf(xlim = c(- 5.5, -4), ylim = c(51.6, 52.2))
```

```{r , include=TRUE,eval = FALSE}

tacsat_fs_land = tacsat_fs_land %>% mutate ( SI_STATE = ifelse  (  SI_SP  >= 1 & SI_SP <= 6 , 'f', 's'  ))


tacsat_fs_df = tacsat_fs_land %>% filter(SI_LAND == FALSE & SI_HARB == FALSE )


st_write( tacsat_fs_df, dsn = ".\\workflow_outputs\\tacsat_fs_df.geojson", layer = "tacsat_fs_df.geojson")
```

### Save outputs

```{r , include=TRUE,eval = FALSE}

#   Save the cleaned EFLALO file 

  save(eflalo_fs, file = '.\\workflow_outputs\\eflalo_fs_qc.RData')


#   Save the cleaned TACSAT file 


  tacsat_fs = tacsat_fs_df
  
  save(tacsat_fs, file = '.\\workflow_outputs\\tacsat_fs_qc.RData')
```

Finally, check well the reported ICES rectangles and the actual rectangles match.

```{r , include=TRUE,eval = FALSE}

tac_geom = tacsat_fs_df %>% st_as_sf( ., coords = c("SI_LONG" ,"SI_LATI"), crs = 4326 )


eflalo_fs %>%  filter ( VE_REF == 'A16337') %>% distinct(LE_CDAT) %>% arrange(LE_CDAT)
ggplot(tac_geom) + geom_sf(aes( color = SI_DATE))



tacsat_fs_df_geom = tac_geom %>%
  st_join ( ices_rect_welsh%>% select ( icesname ) , join = st_intersects, left = T) %>%
  mutate  ( SI_RECT = icesname) 
```